# QBelMan
QBelMan is a repository to simulate several algorithms for queueing bandit problems, like Thompson sampling (ThS) [2], UCB [3], BelMan [1], QBelMan, Q-UCB[4], and Q-ThS[4]. 
The queueing bandit problem tries to match the queues and servers, with unknown arrival and service rates, in order to achive minimum queue length in hold.

References:
1. Basu, D., Senellart, P. and Bressan, S., 2018. BelMan: Bayesian Bandits on the Belief--Reward Manifold. arXiv preprint arXiv:1805.01627. (URL: https://arxiv.org/pdf/1805.01627.pdf)
2.  Agrawal, S. and Goyal, N., 2012, June. Analysis of thompson sampling for the multi-armed bandit problem. In Conference on Learning Theory (pp. 39-1). (URL: http://proceedings.mlr.press/v23/agrawal12/agrawal12.pdf)
3. Auer, P., Cesa-Bianchi, N. and Fischer, P., 2002. Finite-time analysis of the multiarmed bandit problem. Machine learning, 47(2-3), pp.235-256. (URL: https://link.springer.com/content/pdf/10.1023/A:1013689704352.pdf)
4. Krishnasamy, S., Sen, R., Johari, R. and Shakkottai, S., 2016. Regret of queueing bandits. In Advances in Neural Information Processing Systems (pp. 1669-1677). (URL: http://papers.nips.cc/paper/6370-regret-of-queueing-bandits.pdf)
5. Basu, D., Pedrielli, G., Senellart, P., and Bressan, S., 2018. Belman in queue: An information geometric approach to queueing bandits with general distributions.. Working paper.
